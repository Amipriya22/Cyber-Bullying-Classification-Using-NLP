{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You can use the Breast Cancer Wisconsin Dataset. The dataset contains various features computed from digitized images of breast mass, and the task is to predict whether the mass is benign or malignant. You can download the dataset from the UCI Machine Learning Repository using the following URL:\n",
        "\n",
        "Breast Cancer Wisconsin Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
      ],
      "metadata": {
        "id": "Wp5VOsggizXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building an Artificial Neural Network (ANN) for Binary Classification"
      ],
      "metadata": {
        "id": "5TF1rC-OhGvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import Required Libraries\n",
        "\n",
        "Import the necessary libraries: numpy, pandas, tensorflow, and keras."
      ],
      "metadata": {
        "id": "P7frb-RXhG9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras as ks"
      ],
      "metadata": {
        "id": "MU5wsjxghVrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load and Preprocess the Data\n",
        "\n",
        "Load the dataset for your binary classification problem.\n",
        "Preprocess the data as needed (e.g., handling missing values, feature scaling, encoding categorical variables, etc.).\n",
        "Split the dataset into input features (X) and target variable (y)."
      ],
      "metadata": {
        "id": "m-QOJNOVhHAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
        "df = pd.read_csv(url, header=None)\n",
        "# Preprocess the data\n",
        "# Assuming the target variable is in the first column and features in the rest\n",
        "X = df.iloc[:, 2:]  # Features\n",
        "y = df.iloc[:, 1]   # Target variable\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "y= label_encoder.fit_transform(y)\n",
        "y\n"
      ],
      "metadata": {
        "id": "3WMvUd8bhWu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afc366e4-7776-4912-b9e2-2f19a9e23d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Split the Data into Training and Test Sets\n",
        "\n",
        "Split the preprocessed data into training and test sets using the train_test_split function from sklearn.model_selection.\n"
      ],
      "metadata": {
        "id": "NbsL--bnhHDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.10, random_state=42)\n",
        "X_train"
      ],
      "metadata": {
        "id": "uFILFWzsh0Fs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "2a0e2951-a6dd-4b49-a9f2-38754a5f5a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         2      3       4       5        6        7        8        9   \\\n",
              "82   25.220  24.91  171.50  1878.0  0.10630  0.26650  0.33390  0.18450   \n",
              "39   13.480  20.82   88.40   559.2  0.10160  0.12550  0.10630  0.05439   \n",
              "271  11.290  13.04   72.23   388.0  0.09834  0.07608  0.03265  0.02755   \n",
              "79   12.860  18.00   83.19   506.3  0.09934  0.09546  0.03889  0.02315   \n",
              "2    19.690  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790   \n",
              "..      ...    ...     ...     ...      ...      ...      ...      ...   \n",
              "71    8.888  14.64   58.79   244.0  0.09783  0.15310  0.08606  0.02872   \n",
              "106  11.640  18.33   75.17   412.5  0.11420  0.10170  0.07070  0.03485   \n",
              "270  14.290  16.82   90.30   632.6  0.06429  0.02675  0.00725  0.00625   \n",
              "435  13.980  19.62   91.12   599.5  0.10600  0.11330  0.11260  0.06463   \n",
              "102  12.180  20.52   77.22   458.7  0.08013  0.04038  0.02383  0.01770   \n",
              "\n",
              "         10       11  ...      22     23      24      25       26       27  \\\n",
              "82   0.1829  0.06782  ...  30.000  33.62  211.70  2562.0  0.15730  0.60760   \n",
              "39   0.1720  0.06419  ...  15.530  26.02  107.30   740.4  0.16100  0.42250   \n",
              "271  0.1769  0.06270  ...  12.320  16.18   78.27   457.5  0.13580  0.15070   \n",
              "79   0.1718  0.05997  ...  14.240  24.82   91.88   622.1  0.12890  0.21410   \n",
              "2    0.2069  0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450   \n",
              "..      ...      ...  ...     ...    ...     ...     ...      ...      ...   \n",
              "71   0.1902  0.08980  ...   9.733  15.67   62.56   284.4  0.12070  0.24360   \n",
              "106  0.1801  0.06520  ...  13.140  29.26   85.51   521.7  0.16880  0.26600   \n",
              "270  0.1508  0.05376  ...  14.910  20.65   94.44   684.6  0.08567  0.05036   \n",
              "435  0.1669  0.06544  ...  17.040  30.80  113.90   869.3  0.16130  0.35680   \n",
              "102  0.1739  0.05677  ...  13.340  32.84   84.58   547.8  0.11230  0.08862   \n",
              "\n",
              "          28       29      30       31  \n",
              "82   0.64760  0.28670  0.2355  0.10510  \n",
              "39   0.50300  0.22580  0.2807  0.10710  \n",
              "271  0.12750  0.08750  0.2733  0.08022  \n",
              "79   0.17310  0.07926  0.2779  0.07918  \n",
              "2    0.45040  0.24300  0.3613  0.08758  \n",
              "..       ...      ...     ...      ...  \n",
              "71   0.14340  0.04786  0.2254  0.10840  \n",
              "106  0.28730  0.12180  0.2806  0.09097  \n",
              "270  0.03866  0.03333  0.2458  0.06120  \n",
              "435  0.40690  0.18270  0.3179  0.10550  \n",
              "102  0.11450  0.07431  0.2694  0.06878  \n",
              "\n",
              "[512 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63f1d828-378c-4eb8-a8db-bfa8ec146f53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>25.220</td>\n",
              "      <td>24.91</td>\n",
              "      <td>171.50</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>0.10630</td>\n",
              "      <td>0.26650</td>\n",
              "      <td>0.33390</td>\n",
              "      <td>0.18450</td>\n",
              "      <td>0.1829</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>...</td>\n",
              "      <td>30.000</td>\n",
              "      <td>33.62</td>\n",
              "      <td>211.70</td>\n",
              "      <td>2562.0</td>\n",
              "      <td>0.15730</td>\n",
              "      <td>0.60760</td>\n",
              "      <td>0.64760</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.10510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>13.480</td>\n",
              "      <td>20.82</td>\n",
              "      <td>88.40</td>\n",
              "      <td>559.2</td>\n",
              "      <td>0.10160</td>\n",
              "      <td>0.12550</td>\n",
              "      <td>0.10630</td>\n",
              "      <td>0.05439</td>\n",
              "      <td>0.1720</td>\n",
              "      <td>0.06419</td>\n",
              "      <td>...</td>\n",
              "      <td>15.530</td>\n",
              "      <td>26.02</td>\n",
              "      <td>107.30</td>\n",
              "      <td>740.4</td>\n",
              "      <td>0.16100</td>\n",
              "      <td>0.42250</td>\n",
              "      <td>0.50300</td>\n",
              "      <td>0.22580</td>\n",
              "      <td>0.2807</td>\n",
              "      <td>0.10710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>11.290</td>\n",
              "      <td>13.04</td>\n",
              "      <td>72.23</td>\n",
              "      <td>388.0</td>\n",
              "      <td>0.09834</td>\n",
              "      <td>0.07608</td>\n",
              "      <td>0.03265</td>\n",
              "      <td>0.02755</td>\n",
              "      <td>0.1769</td>\n",
              "      <td>0.06270</td>\n",
              "      <td>...</td>\n",
              "      <td>12.320</td>\n",
              "      <td>16.18</td>\n",
              "      <td>78.27</td>\n",
              "      <td>457.5</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.15070</td>\n",
              "      <td>0.12750</td>\n",
              "      <td>0.08750</td>\n",
              "      <td>0.2733</td>\n",
              "      <td>0.08022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>12.860</td>\n",
              "      <td>18.00</td>\n",
              "      <td>83.19</td>\n",
              "      <td>506.3</td>\n",
              "      <td>0.09934</td>\n",
              "      <td>0.09546</td>\n",
              "      <td>0.03889</td>\n",
              "      <td>0.02315</td>\n",
              "      <td>0.1718</td>\n",
              "      <td>0.05997</td>\n",
              "      <td>...</td>\n",
              "      <td>14.240</td>\n",
              "      <td>24.82</td>\n",
              "      <td>91.88</td>\n",
              "      <td>622.1</td>\n",
              "      <td>0.12890</td>\n",
              "      <td>0.21410</td>\n",
              "      <td>0.17310</td>\n",
              "      <td>0.07926</td>\n",
              "      <td>0.2779</td>\n",
              "      <td>0.07918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.690</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.45040</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>8.888</td>\n",
              "      <td>14.64</td>\n",
              "      <td>58.79</td>\n",
              "      <td>244.0</td>\n",
              "      <td>0.09783</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.08606</td>\n",
              "      <td>0.02872</td>\n",
              "      <td>0.1902</td>\n",
              "      <td>0.08980</td>\n",
              "      <td>...</td>\n",
              "      <td>9.733</td>\n",
              "      <td>15.67</td>\n",
              "      <td>62.56</td>\n",
              "      <td>284.4</td>\n",
              "      <td>0.12070</td>\n",
              "      <td>0.24360</td>\n",
              "      <td>0.14340</td>\n",
              "      <td>0.04786</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>0.10840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>11.640</td>\n",
              "      <td>18.33</td>\n",
              "      <td>75.17</td>\n",
              "      <td>412.5</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>0.10170</td>\n",
              "      <td>0.07070</td>\n",
              "      <td>0.03485</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.06520</td>\n",
              "      <td>...</td>\n",
              "      <td>13.140</td>\n",
              "      <td>29.26</td>\n",
              "      <td>85.51</td>\n",
              "      <td>521.7</td>\n",
              "      <td>0.16880</td>\n",
              "      <td>0.26600</td>\n",
              "      <td>0.28730</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.2806</td>\n",
              "      <td>0.09097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>14.290</td>\n",
              "      <td>16.82</td>\n",
              "      <td>90.30</td>\n",
              "      <td>632.6</td>\n",
              "      <td>0.06429</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.00725</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.1508</td>\n",
              "      <td>0.05376</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>20.65</td>\n",
              "      <td>94.44</td>\n",
              "      <td>684.6</td>\n",
              "      <td>0.08567</td>\n",
              "      <td>0.05036</td>\n",
              "      <td>0.03866</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>0.2458</td>\n",
              "      <td>0.06120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>13.980</td>\n",
              "      <td>19.62</td>\n",
              "      <td>91.12</td>\n",
              "      <td>599.5</td>\n",
              "      <td>0.10600</td>\n",
              "      <td>0.11330</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>0.1669</td>\n",
              "      <td>0.06544</td>\n",
              "      <td>...</td>\n",
              "      <td>17.040</td>\n",
              "      <td>30.80</td>\n",
              "      <td>113.90</td>\n",
              "      <td>869.3</td>\n",
              "      <td>0.16130</td>\n",
              "      <td>0.35680</td>\n",
              "      <td>0.40690</td>\n",
              "      <td>0.18270</td>\n",
              "      <td>0.3179</td>\n",
              "      <td>0.10550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>12.180</td>\n",
              "      <td>20.52</td>\n",
              "      <td>77.22</td>\n",
              "      <td>458.7</td>\n",
              "      <td>0.08013</td>\n",
              "      <td>0.04038</td>\n",
              "      <td>0.02383</td>\n",
              "      <td>0.01770</td>\n",
              "      <td>0.1739</td>\n",
              "      <td>0.05677</td>\n",
              "      <td>...</td>\n",
              "      <td>13.340</td>\n",
              "      <td>32.84</td>\n",
              "      <td>84.58</td>\n",
              "      <td>547.8</td>\n",
              "      <td>0.11230</td>\n",
              "      <td>0.08862</td>\n",
              "      <td>0.11450</td>\n",
              "      <td>0.07431</td>\n",
              "      <td>0.2694</td>\n",
              "      <td>0.06878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>512 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f1d828-378c-4eb8-a8db-bfa8ec146f53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63f1d828-378c-4eb8-a8db-bfa8ec146f53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63f1d828-378c-4eb8-a8db-bfa8ec146f53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "# Scaling the testing data\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "WRia3Vwmds7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Create the ANN Model\n",
        "\n",
        "Import the necessary classes and functions from Keras (Sequential, Dense, Activation, Optimizer, etc.).\n",
        "Create an instance of the Sequential class to initialize the model.\n",
        "Add the input layer and hidden layers to the model using the add method.\n",
        "Choose appropriate activation functions for the hidden layers.\n",
        "Add the output layer with a single unit and a suitable activation function for binary classification (e.g., sigmoid).\n",
        "Compile the model with an appropriate loss function (e.g., binary_crossentropy for binary classification) and optimizer."
      ],
      "metadata": {
        "id": "PuzlSgi9hHGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n"
      ],
      "metadata": {
        "id": "35jCb4WHh4cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Train the ANN Model\n",
        "\n",
        "Fit the model to the training data using the fit method.\n",
        "Specify the number of epochs (iterations) and batch size.\n",
        "Monitor the model's performance on the training set during training (e.g., accuracy, loss)."
      ],
      "metadata": {
        "id": "ur9GvrK9hHJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 30)"
      ],
      "metadata": {
        "id": "mM4kPhXBh7aR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c842c035-3b24-405a-f519-fcac5e5792e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "52/52 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.6035\n",
            "Epoch 2/30\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.6934\n",
            "Epoch 3/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.9141\n",
            "Epoch 4/30\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.8887\n",
            "Epoch 5/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.9180\n",
            "Epoch 6/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.9180\n",
            "Epoch 7/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.9199\n",
            "Epoch 8/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.9238\n",
            "Epoch 9/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9258\n",
            "Epoch 10/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.9336\n",
            "Epoch 11/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9336\n",
            "Epoch 12/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9414\n",
            "Epoch 13/30\n",
            "52/52 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9375\n",
            "Epoch 14/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9492\n",
            "Epoch 15/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9473\n",
            "Epoch 16/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9551\n",
            "Epoch 17/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9551\n",
            "Epoch 18/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9648\n",
            "Epoch 19/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9570\n",
            "Epoch 20/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9551\n",
            "Epoch 21/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9590\n",
            "Epoch 22/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9688\n",
            "Epoch 23/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9629\n",
            "Epoch 24/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9648\n",
            "Epoch 25/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9746\n",
            "Epoch 26/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9668\n",
            "Epoch 27/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9707\n",
            "Epoch 28/30\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9727\n",
            "Epoch 29/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.9785\n",
            "Epoch 30/30\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9746\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31c66fbb50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 6 :Evaluate the Model\n",
        "\n",
        "Use the trained model to make predictions on the test set.\n",
        "Evaluate the model's performance using appropriate evaluation metrics (e.g., accuracy).\n"
      ],
      "metadata": {
        "id": "utlFN-VXhHLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(y_pred)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "loss,accuracy=classifier.evaluate(X_test,y_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "6gdxzocKiI4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9600e6f7-7e99-4549-ba19-1f25861a01c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n",
            "[[39  1]\n",
            " [ 1 16]]\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 0.9649\n",
            "0.9649122953414917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment and Improve\n",
        "\n",
        "Experiment with different architectural choices (e.g., number of hidden layers, number of units in each layer) to improve the model's performance.\n",
        "Try different activation functions, optimizers, and learning rates.\n",
        "Consider regularizing the model (e.g., adding dropout, L1/L2 regularization) to prevent overfitting.\n",
        "Iterate on the previous steps until you achieve satisfactory results."
      ],
      "metadata": {
        "id": "-6HbH4m3hHS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In the above, i added a cell for normalising the data by using the scaling method"
      ],
      "metadata": {
        "id": "2aSv8lCIiT9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hints:\n",
        "\n",
        "The Keras documentation (https://keras.io) provides detailed information about the various layers, activation functions, optimizers, and other components you can use in your ANN.\n",
        "Remember to preprocess your data appropriately before training the model.\n",
        "Start with a simple architecture and gradually increase the complexity if needed.\n",
        "Monitor the model's performance during training to detect overfitting or underfitting.\n",
        "Experiment with different hyperparameters to find the best combination for your problem."
      ],
      "metadata": {
        "id": "D5hsGmc3hHWT"
      }
    }
  ]
}